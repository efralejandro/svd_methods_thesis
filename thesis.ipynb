{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aw1d3cRxd7BO",
        "outputId": "81bfdb1f-a79b-4e93-d5c4-533832c91d16"
      },
      "outputs": [],
      "source": [
        "!!pip install torch torchvision\n",
        "!!pip install tensorly\n",
        "!!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExWh6We9nyab",
        "outputId": "86d729a0-61f3-4a62-d33c-259ce389022c"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agXZUzDB1xcF"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUJ4qGKfdBeA"
      },
      "source": [
        "Obtención y preprocesamiento del dataset MNIST de números escritos a mano."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ioEgxo8-PZ6",
        "outputId": "64f763b2-a8c3-49f6-9fe3-475bfb745adb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import tensorly as tl\n",
        "from tqdm import tqdm\n",
        "tl.set_backend('pytorch')\n",
        "\n",
        "# Select device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Transform dataset to tensor\n",
        "transform = transforms.Compose([\n",
        "                                lambda img: transforms.functional.rotate(img, 270),\n",
        "                                lambda img: transforms.functional.hflip(img),\n",
        "                                transforms.GaussianBlur(5, sigma=0.9), # Applying gaussian blur to reduce noise\n",
        "                                transforms.ToTensor()\n",
        "                              ])\n",
        "\n",
        "\n",
        "# Download and load the training dataset\n",
        "train_set = datasets.EMNIST(root='./data', split='digits', train=True, transform=transform, download=True)\n",
        "print(train_set.classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNHzRjSwfiPT"
      },
      "source": [
        "Cargando el Dataset en su **forma matricial**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmMDU9hS2vSr",
        "outputId": "55914d83-99a8-499f-b440-c47276266718"
      },
      "outputs": [],
      "source": [
        "number_of_classes = len(train_set.classes)\n",
        "char_matrices = []\n",
        "for char in range(number_of_classes):\n",
        "  char_mask = train_set.targets == char\n",
        "  char_images = train_set.data[char_mask]\n",
        "  if len(char_images) == 0:\n",
        "    continue  # Skip empty masks\n",
        "\n",
        "  # Shuffle the indices of the images\n",
        "  shuffled_indices = torch.randperm(len(char_images))\n",
        "  char_images = char_images[shuffled_indices]\n",
        "\n",
        "  char_matrix = torch.stack([image.flatten() for image in char_images])\n",
        "  char_matrices.append(char_matrix.T)\n",
        "  print(char_matrix.T.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUHUPNeFfnHC"
      },
      "source": [
        "Cargando el dataset en su **forma tensorial**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oe1K6tqmem8"
      },
      "outputs": [],
      "source": [
        "# Initialize char_tensors as a list of tensors filled with zeros\n",
        "char_tensors = []\n",
        "# Loop over each character and stack its images into a tensor\n",
        "for char in range(number_of_classes):\n",
        "  char_mask = train_set.targets == char\n",
        "  char_images = train_set.data[char_mask]\n",
        "  if len(char_images) == 0:\n",
        "    continue  # Skip empty masks\n",
        "\n",
        "  # Shuffle the indices of the images\n",
        "  shuffled_indices = torch.randperm(len(char_images))\n",
        "  char_images = char_images[shuffled_indices]\n",
        "\n",
        "  char_tensor = torch.stack([image for image in char_images])\n",
        "  char_tensor = char_tensor.permute(1, 2, 0)  # Change the order of tensor dimensions ijk -> ikj\n",
        "  char_tensors.append(char_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nvph5BJU2ceB"
      },
      "source": [
        "# Método 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Y_Z7seNZ3jo"
      },
      "source": [
        "La data del dataset MNIST se interpreta en forma de vectores que se apilan para generar una matriz."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qp9KER2O21tk"
      },
      "source": [
        "Cálculo de $SVD(E_k)$ para cada $E_k$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbUsYMKX272V"
      },
      "outputs": [],
      "source": [
        "Ek_svd = []\n",
        "\n",
        "for A in char_matrices:\n",
        "  A = A.float().to(device)\n",
        "  U_, S_, Vh_ = torch.linalg.svd(A, full_matrices=False)\n",
        "  Ek_svd.append((A, U_, S_, Vh_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryO4feRB57zi"
      },
      "source": [
        "Ejecutando una prueba con el modelo alcanzado para un dígito aleatorio extraído del conjunto de pruebas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Clrgk29Z57F_",
        "outputId": "4af481fb-00be-484a-c124-29bc11bbf768"
      },
      "outputs": [],
      "source": [
        "def predict_single_svd1(z, Ek_svd):\n",
        "  residuals = []\n",
        "  for (A, U, S, Vh) in Ek_svd:\n",
        "    V = Vh.T\n",
        "    res = torch.zeros(Vh.shape[1]).to(device)\n",
        "    for i in range (0, S.shape[0]):\n",
        "      if(S[i] == 0): # In this case, the original matrix A was rank-deficient. Which means we can only approximate x in ||Ax - b||\n",
        "        break\n",
        "      res += torch.dot(U[:, i], z).item() / S[i].item() * V[:,i]\n",
        "    res = A @ res\n",
        "    res = torch.linalg.vector_norm(res - z, ord=2).item()\n",
        "    residuals.append(res)\n",
        "  return np.argmin(residuals)\n",
        "\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Test on random digit from dataset\n",
        "random_index = random.randint(0, len(train_set) - 1)\n",
        "random_image = train_set.data[random_index]\n",
        "random_label = train_set.targets[random_index]\n",
        "\n",
        "y_pred = predict_single_svd1(random_image.T.to(device).flatten().float(), Ek_svd)\n",
        "\n",
        "plt.imshow(random_image.T, cmap='gray')\n",
        "plt.show()\n",
        "print('pred: ', y_pred, 'gt: ', random_label.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuVEfCkq6HQ2",
        "outputId": "5d74911b-6e27-4bf8-b37e-fdc6bdba5b05"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def compute_accuracy_and_time_svd1(k, subset_size=0.05):\n",
        "  total_accuracy = 0\n",
        "  total_time_taken = 0\n",
        "  for i in range(k):\n",
        "      start_time = time.time()\n",
        "      # Test model accuracy on validation set\n",
        "      validation_set = datasets.EMNIST(root='./data', split='digits', train=False, transform=transform, download=True)\n",
        "\n",
        "      from torch.utils.data import Subset\n",
        "      # Create a subset of the validation dataset with subset_size % of the data\n",
        "      subset_indices = torch.randperm(len(validation_set))[:int(len(validation_set)*subset_size)]\n",
        "      validation_subset = Subset(validation_set, subset_indices)\n",
        "\n",
        "      validationLoader = torch.utils.data.DataLoader(validation_subset, batch_size=1, shuffle=True)\n",
        "\n",
        "      # Test each image and compute accuracy\n",
        "      total = 0\n",
        "      correct = 0\n",
        "      progress_bar = tqdm(enumerate(validationLoader), total=len(validationLoader))\n",
        "      progress_bar.set_description(f'Processing subset for {i}')\n",
        "      for idx, (image, label) in progress_bar:\n",
        "          image = image[0,0,:,:]\n",
        "          image, label = image.cuda(), label.cuda()\n",
        "          pred = predict_single_svd1(image.T.flatten().float(), Ek_svd)\n",
        "          if pred == label:\n",
        "              correct += 1\n",
        "          total += 1\n",
        "\n",
        "      accuracy = correct / total\n",
        "      total_accuracy += accuracy\n",
        "\n",
        "      end_time = time.time()\n",
        "      time_taken = end_time - start_time\n",
        "      total_time_taken += time_taken\n",
        "\n",
        "      print(f'Iteration {i+1} - Accuracy: {accuracy:.4f}, Time taken: {time_taken:.2f}s')\n",
        "\n",
        "  average_accuracy = total_accuracy / k\n",
        "  average_time_taken = total_time_taken / k\n",
        "\n",
        "  print('\\n\\n')\n",
        "  print('--------------------------')\n",
        "  print('|   Average Performance   |')\n",
        "  print('--------------------------')\n",
        "  print(f'| Accuracy | Time (in s) |')\n",
        "  print('--------------------------')\n",
        "  print(f'|  {average_accuracy:.4f}  |   {average_time_taken:.2f}    |')\n",
        "  print('--------------------------')\n",
        "\n",
        "  return (average_accuracy, average_time_taken)\n",
        "\n",
        "# Compute accuracy and execution time\n",
        "k=10\n",
        "acc, time_taken = compute_accuracy_and_time_svd1(k, 0.005)\n",
        "print(f'Average accuracy over {k} iterations: {acc:.4f}')\n",
        "print(f'Average time taken over {k} iterations: {time_taken:.2f} seconds')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v88tNXLX0jco"
      },
      "source": [
        "# Método 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e39qeiTdm9S"
      },
      "source": [
        "Cálculo de $SVD(E_k)$ para cada $E_k$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNcVlfz3d7T-"
      },
      "outputs": [],
      "source": [
        "Uk_svd = []\n",
        "\n",
        "for A in char_matrices:\n",
        "  A = A.float().to(device)\n",
        "  U_, _, _ = torch.linalg.svd(A, full_matrices=False)\n",
        "  Uk_svd.append(U_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1K6hAPCm7Sy"
      },
      "source": [
        "Cálculo de $(I - U_kU_k^T)$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0pTkF1xm6LL"
      },
      "outputs": [],
      "source": [
        "def uk_prepare(Uk_svd, k):\n",
        "  Uk_pre = []\n",
        "  for i, Uk in enumerate(Uk_svd):\n",
        "    Uk = Uk[:,:k].to(device)\n",
        "    trunc = torch.eye(Uk.shape[0], Uk.shape[0]).to(device) - torch.matmul(Uk, Uk.T)\n",
        "    Uk_pre.append(trunc)\n",
        "  return Uk_pre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhT3e6mVeu4m"
      },
      "outputs": [],
      "source": [
        "Uk_pre = uk_prepare(Uk_svd, k=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gt6Qzv1Z1dvO"
      },
      "source": [
        "Ejecutando una prueba con el modelo alcanzado para un dígito aleatorio extraído del conjunto de pruebas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "Y9_Jkc1YtDu_",
        "outputId": "ae0b94de-3afe-4fd4-afa8-2f93325d0fbd"
      },
      "outputs": [],
      "source": [
        "def predict_single_svd2(z, Uk_pre_):\n",
        "  residuals = torch.zeros(len(Uk_pre_), device=z.device)\n",
        "  for i, A in enumerate(Uk_pre_):\n",
        "      res = torch.matmul(A, z)\n",
        "      residuals[i] = torch.linalg.vector_norm(res, ord=2)\n",
        "\n",
        "  return torch.argmin(residuals).item()\n",
        "\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Test on random digit from dataset\n",
        "random_index = random.randint(0, len(train_set) - 1)\n",
        "random_image = train_set.data[random_index]\n",
        "random_label = train_set.targets[random_index]\n",
        "\n",
        "y_pred = predict_single_svd2(random_image.flatten().float().to(device), Uk_pre)\n",
        "\n",
        "plt.imshow(random_image.T, cmap='gray')\n",
        "plt.show()\n",
        "print('pred: ', y_pred, 'gt: ', random_label.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "no8k5lAv0m4v",
        "outputId": "1244bdae-0c7e-4408-a366-e354c2c1188a"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from tabulate import tabulate\n",
        "\n",
        "validation_set = datasets.EMNIST(root='./data', split='digits', train=False, transform=transform, download=True)\n",
        "\n",
        "acc_values = []\n",
        "time_values = []\n",
        "counts_values = []\n",
        "\n",
        "min_lambda = 10\n",
        "max_lambda = 11\n",
        "\n",
        "for k in range(min_lambda, max_lambda):\n",
        "  acc, time_taken, counts, correct_counts = compute_accuracy_and_time_for_method(Uk_svd, preproc_method=uk_prepare, method=predict_single_svd2, kappa=k, validation_set=validation_set, compute_confusion_matrix=False)\n",
        "  acc_values.append(acc)\n",
        "  time_values.append(time_taken)\n",
        "  counts_values.append(correct_counts/counts)\n",
        "\n",
        "# Display accuracy table\n",
        "header = [\"λ\"] + [str(i) for i in range(number_of_classes)] + [\"Precisión\", \"Time (in s)\"]\n",
        "table = []\n",
        "for i in range(min_lambda, max_lambda):\n",
        "  arr_index = i-min_lambda\n",
        "  row = [i] + counts_values[arr_index].tolist() + [acc_values[arr_index], time_values[arr_index]]\n",
        "  table.append(row)\n",
        "\n",
        "print(tabulate(table, headers=header))\n",
        "\n",
        "# Plot accuracy vs k for each class\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "for i in range(number_of_classes):\n",
        "  ax.plot(range(min_lambda, max_lambda), np.array(counts_values)[0:, i], label=f\"Clase {i}\")\n",
        "ax.set_yscale('log', base=2)\n",
        "ax.set_xlabel(\"Valor de λ\")\n",
        "ax.set_ylabel(\"Precisión\")\n",
        "ax.set_title(\"Precisión por dígito vs Valor de λ\")\n",
        "ax.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot the accuracy vs k graph\n",
        "plt.plot(range(min_lambda, max_lambda), acc_values)\n",
        "plt.xlabel('Valor de λ')\n",
        "plt.ylabel('Precisión')\n",
        "plt.title('Precisión vs Valor de λ')\n",
        "plt.show()\n",
        "\n",
        "# Plot execution time vs. value of k\n",
        "plt.plot(range(min_lambda, max_lambda), time_values)\n",
        "plt.xlabel('Valor de λ')\n",
        "plt.ylabel('Tiempo de ejecución (s)')\n",
        "plt.title('Tiempo de ejecución vs Valor de λ')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "9BCHKVxZ7BK8",
        "outputId": "017a98f8-94ed-4768-da9a-6b50f5ea702b"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "\n",
        "# Define a list of colors and line styles for the lines\n",
        "colors = ['blue', 'orange', 'green', 'red', 'purple', 'brown', 'pink', 'gray',\n",
        "          'olive', 'cyan', 'magenta', 'lime', 'teal', 'navy', 'maroon', 'gold',\n",
        "          'indigo', 'peru', 'darkslategray', 'coral', 'royalblue', 'mediumvioletred',\n",
        "          'lightseagreen', 'darkkhaki', 'darkorchid']\n",
        "line_styles = ['-', '--', '-.', ':']\n",
        "\n",
        "# Define a list of class labels as letters from the alphabet (A-Z)\n",
        "class_labels = list(string.ascii_uppercase)[:number_of_classes-1]\n",
        "\n",
        "# Plot accuracy vs k for each class\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "for i in range(number_of_classes):\n",
        "    color = colors[i % len(colors)]\n",
        "    line_style = line_styles[i % len(line_styles)]\n",
        "    ax.plot(range(min_lambda, max_lambda), np.array(counts_values)[:, i],\n",
        "            color=color, linestyle=line_style, label=f\"Clase {class_labels[i-1]}\")\n",
        "ax.set_yscale('log', base=2)\n",
        "ax.set_xlabel(\"Valor de λ\")\n",
        "ax.set_ylabel(\"Precisión\")\n",
        "ax.set_title(\"Precisión por letra vs Valor de λ\")\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-Fk_7OKU7cW",
        "outputId": "e64af861-2042-4919-b466-695f1d5c99e0"
      },
      "outputs": [],
      "source": [
        "compute_accuracy_and_time_for_method(Uk_svd, preproc_method=uk_prepare, method=predict_single_svd2, kappa=10, validation_set=validation_set, compute_confusion_matrix=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKbmy1Rq1r_n"
      },
      "source": [
        "# Método 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QO4gPtHy-Kf8"
      },
      "source": [
        "\n",
        "Se forman 10 tensores $E_k$, donde $k$ representa la etiqueta de los dígitos que se hallan en el tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TAJBwDkd1Ni"
      },
      "source": [
        "Cálculo de $HOSVD(\\mathcal{A})$\n",
        "\n",
        "Para $n=1,\\ldots,N$\n",
        "\n",
        "\n",
        "*   Hallar $A_{(n)}$\n",
        "*   Hallar la SVD de cada $A_{(n)}$: $A_{(n)} = U^{(n)}\\Sigma^{(n)}\\left[V^{(n)}\\right]^T$\n",
        "* Luego, $\\mathcal{S} = \\mathcal{A} \\times_1 (U^{(1)})^T \\times_2 (U^{(2)})^T \\times_3 \\ldots \\times_N (U^{(N)})^T$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P43OsIi_dz0b"
      },
      "outputs": [],
      "source": [
        "def hosvd(T):\n",
        "  U = []\n",
        "  S = []\n",
        "  Vh = []\n",
        "  T_core = T.clone()\n",
        "  for i, ni in enumerate(T.shape):\n",
        "    # Compute the unfolding of the tensor\n",
        "    T_unfolded = tl.unfold(T, i)\n",
        "    # Compute the SVD of the unfolded tensor tensor\n",
        "    U_, S_, Vh_ = torch.linalg.svd(T_unfolded.to(device), full_matrices=False)\n",
        "    U.append(U_)\n",
        "    S.append(S_)\n",
        "    Vh.append(Vh_)\n",
        "    T_core = tl.tenalg.mode_dot(T_core.to(device), U_.T, i)\n",
        "  return (T_core, [U, S, Vh])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_3_Bvxlc4rF"
      },
      "source": [
        "Calcular $HOSVD(E_k)$ para cada $E_k$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIY0j3B8nN0W"
      },
      "outputs": [],
      "source": [
        "Ek_hosvd = []\n",
        "\n",
        "for T in char_tensors:\n",
        "  T = T.float()\n",
        "  T_core, (U, _, _) = hosvd(T)\n",
        "  Ek_hosvd.append((T_core, U[:2])) # Appending only U^(1) and U^(2) along with the core tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEfYZ0nGhQWl"
      },
      "source": [
        "Cálculo de $A_v$ ($\\mathcal{A} = \\sum_{v=1}^{k}A_v \\times_3 u_v$)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UcKqU_sCxni"
      },
      "outputs": [],
      "source": [
        "def hosvd_trunc(Ek_hosvd, k):\n",
        "  Ek_trunc = []\n",
        "  for i, svd in enumerate(Ek_hosvd):\n",
        "    A = []\n",
        "    #Obtaining truncated svd expression\n",
        "    for i in range (k):\n",
        "      trunc = svd[0][:,:,i].to(device)\n",
        "      trunc = tl.tenalg.mode_dot(trunc, svd[1][0].to(device), 0)\n",
        "      trunc = tl.tenalg.mode_dot(trunc, svd[1][1].to(device), 1)\n",
        "      A.append((trunc, tl.tenalg.inner(trunc, trunc, n_modes=None).item()))\n",
        "    Ek_trunc.append(A)\n",
        "  return Ek_trunc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZI2h6ptjmIO"
      },
      "source": [
        "Obtener el conjunto de $A_v$ para cada tensor $E_k$ cuya HOSVD ha sido calculada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgrF0yrykAB8"
      },
      "outputs": [],
      "source": [
        "Ek_trunc = hosvd_trunc(Ek_hosvd, k=20) # k is a hyper-parameter whose impact can be analyzed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxYaDmhmkh3-"
      },
      "source": [
        "Ejecutando una prueba con el modelo alcanzado para un dígito aleatorio extraído del conjunto de pruebas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "1Rg9WjZpgTVd",
        "outputId": "4548829b-6094-44e9-d6a7-c54ad8c8f3bc"
      },
      "outputs": [],
      "source": [
        "def r_hosvd(Z, A):\n",
        "  z_dot_aj = sum((tl.tenalg.inner(Z, Aj, n_modes=None).item() / Aj_) * Aj for (Aj, Aj_) in A)\n",
        "  return torch.linalg.matrix_norm(Z - z_dot_aj).item()\n",
        "\n",
        "def predict_single_hosvd(Z, svd_):\n",
        "  residuals = torch.zeros(len(svd_), device=Z.device)\n",
        "  for i, A in enumerate(svd_):\n",
        "    res = r_hosvd(Z, A)\n",
        "    residuals[i] = res\n",
        "  return torch.argmin(residuals).item()\n",
        "\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Test on random digit from dataset\n",
        "random_index = random.randint(0, len(train_set) - 1)\n",
        "random_image = train_set.data[random_index]\n",
        "random_label = train_set.targets[random_index]\n",
        "\n",
        "y_pred = predict_single_hosvd(random_image.to(device), Ek_trunc)\n",
        "\n",
        "plt.imshow(random_image.T, cmap='gray')\n",
        "plt.show()\n",
        "print('pred: ', y_pred, 'gt: ', random_label.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "28IwyQdcso0v",
        "outputId": "d1b31a35-f5a8-4218-ba04-c432ed69771c"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from tabulate import tabulate\n",
        "\n",
        "validation_set = datasets.EMNIST(root='./data', split='digits', train=False, transform=transform, download=True)\n",
        "\n",
        "acc_values = []\n",
        "time_values = []\n",
        "counts_values = []\n",
        "\n",
        "min_lambda = 10\n",
        "max_lambda = 41\n",
        "step=2\n",
        "\n",
        "for k in range(min_lambda, max_lambda, step):\n",
        "  acc, time_taken, counts, correct_counts = compute_accuracy_and_time_for_method(\n",
        "                                                                                Ek_hosvd,\n",
        "                                                                                preproc_method=hosvd_trunc,\n",
        "                                                                                method=predict_single_hosvd,\n",
        "                                                                                kappa=k,\n",
        "                                                                                validation_set=validation_set,\n",
        "                                                                                compute_confusion_matrix=False,\n",
        "                                                                                do_not_flatten=True)\n",
        "  acc_values.append(acc)\n",
        "  time_values.append(time_taken)\n",
        "  counts_values.append(correct_counts/counts)\n",
        "\n",
        "# Display accuracy table\n",
        "header = [\"λ\"] + [str(i) for i in range(number_of_classes)] + [\"Precisión\", \"Tiempo (s)\"]\n",
        "table = []\n",
        "for i in range(min_lambda, max_lambda, step):\n",
        "  arr_index = round((i-min_lambda)/2)\n",
        "  row = [i] + counts_values[arr_index].tolist() + [acc_values[arr_index], time_values[arr_index]]\n",
        "  table.append(row)\n",
        "\n",
        "print(tabulate(table, headers=header))\n",
        "\n",
        "# Plot the accuracy vs k graph\n",
        "plt.plot(range(min_lambda, max_lambda, step), acc_values)\n",
        "plt.xlabel('Valor de λ')\n",
        "plt.ylabel('Precisión')\n",
        "plt.title('Precisión vs Valor de λ')\n",
        "plt.show()\n",
        "\n",
        "# Plot execution time vs. value of k\n",
        "plt.plot(range(min_lambda, max_lambda, step), time_values)\n",
        "plt.xlabel('Valor de λ')\n",
        "plt.ylabel('Tiempo de ejecución (s)')\n",
        "plt.title('Tiempo de ejecución vs Valor de λ')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "Yu_Pg5kDYV4g",
        "outputId": "bdec0711-784a-45dc-fba1-6c3d7025f734"
      },
      "outputs": [],
      "source": [
        "# Plot accuracy vs k for each class\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "for i in range(number_of_classes):\n",
        "  ax.plot(range(min_lambda, max_lambda, 2), np.array(counts_values)[:, i], label=f\"Clase {i}\")\n",
        "ax.set_yscale('log', base=2)\n",
        "ax.set_xlabel(\"Valor de λ\")\n",
        "ax.set_ylabel(\"Precisión\")\n",
        "ax.set_title(\"Precisión por dígito vs Valor de λ\")\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TijIk7MStl-z"
      },
      "source": [
        "# RandNLDA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Mu5UlEatlG7"
      },
      "outputs": [],
      "source": [
        "def cwt_matrix(n_rows, n_columns):\n",
        "  S = torch.zeros(n_rows, n_columns).to(device)\n",
        "  nz_positions = np.random.randint(0, n_rows, n_columns)\n",
        "  values = np.random.choice([1, -1], n_columns)\n",
        "  for i in range(n_columns):\n",
        "      S[nz_positions[i]][i] = values[i]\n",
        "\n",
        "  return S\n",
        "\n",
        "def clarkson_woodruff_transform(input_matrix, sketch_size):\n",
        "  S = cwt_matrix(sketch_size, input_matrix.shape[0])\n",
        "  return S @ input_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fweD21y5H74"
      },
      "outputs": [],
      "source": [
        "def uk_prime_prepare(Uk_svd, k_t):\n",
        "  k, t = k_t\n",
        "  Uk_pre = []\n",
        "  for i, Uk in enumerate(Uk_svd):\n",
        "    Uk = Uk[:,:k].to(device)\n",
        "    trunc = torch.eye(Uk.shape[0], Uk.shape[0], device=device) - torch.matmul(Uk, Uk.T)\n",
        "    trunc = clarkson_woodruff_transform(trunc, t)\n",
        "    Uk_pre.append(trunc)\n",
        "  return Uk_pre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZBHE1wd5cIC"
      },
      "outputs": [],
      "source": [
        "Uk_svd = []\n",
        "\n",
        "for A in char_matrices:\n",
        "  A = A.float().to(device)\n",
        "  U_, _, _ = torch.linalg.svd(A.to(device), full_matrices=False)\n",
        "  Uk_svd.append(U_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TF7Qxcb5kIm"
      },
      "outputs": [],
      "source": [
        "Uk_prime_pre = uk_prime_prepare(Uk_svd, (8, int(784 * 0.8)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Ag5GwlDA5rGe",
        "outputId": "af9174ef-5b15-4cd1-ac75-7b836a52ae7f"
      },
      "outputs": [],
      "source": [
        "def predict_single_randnla(z, Uk_pre_):\n",
        "    residuals = torch.zeros(len(Uk_pre_), device=z.device)\n",
        "\n",
        "    for i, A in enumerate(Uk_pre_):\n",
        "        res = torch.matmul(A, z)  # Matrix-vector multiplication using broadcasting\n",
        "        residuals[i] = torch.linalg.vector_norm(res, ord=2)\n",
        "\n",
        "    return torch.argmin(residuals).item() + 1\n",
        "\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Test on random digit from dataset\n",
        "random_index = random.randint(0, len(train_set) - 1)\n",
        "random_image = train_set.data[random_index]\n",
        "random_label = train_set.targets[random_index]\n",
        "\n",
        "y_pred = predict_single_randnla(random_image.flatten().float().to(device), Uk_prime_pre)\n",
        "\n",
        "plt.imshow(random_image.T, cmap='gray')\n",
        "plt.show()\n",
        "print('pred: ', y_pred, 'gt: ', random_label.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BShP7_IEywdU",
        "outputId": "d63c68e5-af4b-425a-8570-f63b9aed1516"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from tabulate import tabulate\n",
        "\n",
        "validation_set = datasets.EMNIST(root='./data', split='letters', train=False, transform=transform, download=True)\n",
        "\n",
        "min_lambda = 10\n",
        "max_lambda = 41\n",
        "step =  3\n",
        "proportions = np.arange(1.0, 0.4, -0.2)\n",
        "ts = [int(784 * proportion) for proportion in proportions]\n",
        "\n",
        "acc_values = []\n",
        "time_values = []\n",
        "counts_values = []\n",
        "\n",
        "for t in ts:\n",
        "    acc_t_values = []\n",
        "    time_t_values = []\n",
        "    counts_t_values = []\n",
        "    for k in range(min_lambda, max_lambda, step):\n",
        "        acc, time_taken, counts, correct_counts = compute_accuracy_and_time_for_method(\n",
        "                                                                                      Uk_svd,\n",
        "                                                                                      preproc_method=uk_prime_prepare,\n",
        "                                                                                      method=predict_single_randnla,\n",
        "                                                                                      kappa=(k, t),\n",
        "                                                                                      validation_set=validation_set,\n",
        "                                                                                      compute_confusion_matrix=False)\n",
        "        acc_t_values.append(acc)\n",
        "        time_t_values.append(time_taken)\n",
        "        counts_t_values.append(correct_counts / counts)\n",
        "    acc_values.append(acc_t_values)\n",
        "    time_values.append(time_t_values)\n",
        "    counts_values.append(counts_t_values)\n",
        "\n",
        "# Display accuracy table\n",
        "header = [\"λ\", \"t\"] + [str(i) for i in range(number_of_classes)] + [\"Precisión\", \"Tiempo (s)\"]\n",
        "table = []\n",
        "for i in range(len(ts)):\n",
        "    for j in range(0, max_lambda-min_lambda, step):\n",
        "        row = [j, ts[i]]\n",
        "        row += counts_values[i][j//step].tolist()\n",
        "        row += [acc_values[i][j//step], time_values[i][j//step]]\n",
        "        table.append(row)\n",
        "\n",
        "print(tabulate(table, headers=header))\n",
        "\n",
        "# Plot the accuracy vs k graph\n",
        "for j in range(len(ts)):\n",
        "    plt.plot(range(min_lambda, max_lambda, step), acc_values[j], label=f\"t = {ts[j]}\")\n",
        "plt.xlabel('Valor de λ')\n",
        "plt.ylabel('Precisión')\n",
        "plt.title('Precisión vs Valor de λ')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot execution time vs. value of k\n",
        "for j in range(len(ts)):\n",
        "    plt.plot(range(min_lambda, max_lambda, step), time_values[j], label=f\"t = {ts[j]}\")\n",
        "plt.xlabel('Valor de λ')\n",
        "plt.ylabel('Tiempo de ejecución (s)')\n",
        "plt.title('Tiempo de ejecución vs Valor de λ')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNAwoPks4qqD"
      },
      "source": [
        "# Otros métodos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iau_k4Qx4uvG"
      },
      "outputs": [],
      "source": [
        "def compute_accuracy_and_time_for_method(data, preproc_method=None, method=None, kappa=1, validation_set=None, compute_confusion_matrix=False, do_not_flatten=False):\n",
        "  start_time = time.time()\n",
        "  start_value = 0 if number_of_classes == 10 else 1\n",
        "\n",
        "  preproc_data = None\n",
        "  if(preproc_method is not None):\n",
        "    preproc_data = preproc_method(data, kappa)\n",
        "\n",
        "  # Test model accuracy on validation set\n",
        "  validationLoader = torch.utils.data.DataLoader(validation_set, batch_size=1, shuffle=True)\n",
        "\n",
        "  # Test each image and compute accuracy\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  counts = np.zeros(number_of_classes, dtype=int)  # To keep count of each type of digit\n",
        "  correct_counts = np.zeros(number_of_classes , dtype=int)  # To keep count of correctly classified digits\n",
        "\n",
        "  if(compute_confusion_matrix == True):\n",
        "    confusion_matrix = np.zeros((number_of_classes, number_of_classes), dtype=int)  # To compute the confusion matrix\n",
        "\n",
        "  for idx, (image, label) in enumerate(tqdm(validationLoader)):\n",
        "\n",
        "    image = image[0,0,:,:]\n",
        "    image = image.to(device).T.float()\n",
        "\n",
        "    if(preproc_data is not None):\n",
        "      if(do_not_flatten == False):\n",
        "        image = image.flatten()\n",
        "      pred = method(image, preproc_data)\n",
        "    else:\n",
        "      pred = method(image, data)\n",
        "\n",
        "    counts[label] += 1\n",
        "    if pred == label:\n",
        "      correct_counts[label] += 1\n",
        "      correct += 1\n",
        "    total += 1\n",
        "\n",
        "    if(compute_confusion_matrix == True):\n",
        "      confusion_matrix[label, pred] += 1  # Update the confusion\n",
        "\n",
        "  accuracy = correct / total\n",
        "  end_time = time.time()\n",
        "  execution_time = end_time - start_time\n",
        "\n",
        "  if(compute_confusion_matrix == True):\n",
        "    # Plot the confusion matrix\n",
        "    fig, ax = plt.subplots(figsize=(10, 10))\n",
        "    ax.matshow(confusion_matrix, cmap=plt.cm.Blues)\n",
        "\n",
        "    for i in range(start_value, confusion_matrix.shape[0]):\n",
        "        for j in range(start_value, confusion_matrix.shape[1]):\n",
        "            ax.text(j, i, str(confusion_matrix[i, j]), ha='center', va='center')\n",
        "    ax.set_xlabel('Valor predicho')\n",
        "    ax.set_ylabel('Valor real')\n",
        "    plt.show()\n",
        "\n",
        "  return (accuracy, execution_time, counts, correct_counts)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Nvph5BJU2ceB",
        "KNAwoPks4qqD"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
